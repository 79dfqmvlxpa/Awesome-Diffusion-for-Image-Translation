# Diffusion for Image-to-Image Translation

```Latex
**Here is the Paper Name.**<br>
*[Author 1](homepage), Author 2, and Author 3.*<br>
Conference or Journal Year. [[PDF](link)] <br>
[[Project](link)] [[Github](link)] [[Video](link)] [[Data](link)]
```

Download all PDF files
```
python download.py
```


- [2023](#2023)
- [2022](#2022)
- [2021](#2021)


## 2023

**I2SB: Image-to-Image Schrödinger Bridge.** <br>
*Guan-Horng Liu, Arash Vahdat, De-An Huang, Evangelos A. Theodorou, Weili Nie and Anima Anandkumar.*<br>
arxiv2023. [[PDF](https://arxiv.org/abs/2302.05872)] <br>
[[Project](https://i2sb.github.io/)] [[Github](https://github.com/NVlabs/I2SB)]

**ReGeneration Learning of Diffusion Models with Rich Prompts for Zero-Shot Image Translation.**<br>
*Yupei Lin, Sen Zhang, Xiaojun Yang, Xiao Wang and Yukai Shi.*<br>
arxiv2023. [[PDF](http://arxiv.org/abs/2305.04651v1)] <br>
[[Project](https://yupeilin2388.github.io/publication/ReDiffuser)] 

**DiffI2I: Efficient Diffusion Model for Image-to-Image Translation.**<br>
*Bin Xia, Yulun Zhang, Shiyin Wang, Yitong Wang, Xinglong Wu, Yapeng Tian, Wenming Yang, Radu Timotfe and Luc Van Gool.*<br>
arxiv2023. [[PDF](http://arxiv.org/abs/2308.13767v1)]

**Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer.**<br>
*Serin Yang, Hyunmin Hwang and Jong Chul Ye.*<br>
arxiv2023. [[PDF](https://arxiv.org/abs/2303.08622)] <br>
[[Github](https://github.com/ouhenio/text-guided-diffusion-style-transfer)] 

**PAI-Diffusion: Constructing and Serving a Family of Open Chinese Diffusion Models for Text-to-image Synthesis on the Cloud.**<br>
*Chengyu Wang, Zhongjie Duan, Bingyan Liu, Xinyi Zou, Cen Chen, Kui Jia and Jun Huang.*<br>
arxiv2023. [[PDF](https://arxiv.org/abs/2309.05534)] 

**ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer.**<br>
*Zachary Horvitz, Ajay Patel, Chris Callison-Burch, Zhou Yu and Kathleen McKeown.*<br>
arxiv2023. [[PDF](https://arxiv.org/abs/2308.15459)] 

**StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion Models.**<br>
*Zhizhong Wang, Lei Zhao and Wei Xing.*<br>
arxiv2023. [[PDF](https://arxiv.org/abs/2308.07863)]

**DIFF-NST: Diffusion Interleaving For deFormable Neural Style Transfer.**<br>
*Dan Ruta, Gemma Canet Tarrés, Andrew Gilbert, Eli Shechtman, Nicholas Kolkin and John Collomosse。*<br>
arxiv2023. [[PDF](https://arxiv.org/abs/2307.04157)]

**ArtFusion: Controllable Arbitrary Style Transfer using Dual Conditional Latent Diffusion Models.**<br>
*Dar-Yen Chen.*<br>
arxiv2023. [[PDF](https://arxiv.org/abs/2306.09330)]

**Interpretable Style Transfer for Text-to-Speech with ControlVAE and Diffusion Bridge.**<br>
*Wenhao Guan, Tao Li, Yishuang Li, Hukai Huang, Qingyang Hong and Lin Li.*<br>
arxiv2023. [[PDF](https://arxiv.org/abs/2306.04301)]

**Fine-grained Text Style Transfer with Diffusion-Based Language Models.**<br>
*Yiwei Lyu, Tiange Luo, Jiacheng Shi, Todd C. Hollon and Honglak Lee.*<br>
arxiv2023. [[PDF](https://arxiv.org/abs/2305.19512)]

## 2022

**Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation.**<br>
*Narek Tumanyan, Michal Geyer, Shai Bagon and Tali Dekel.*<br>
CVPR2023. [[PDF](https://arxiv.org/abs/2211.12572)] <br>
[[Github](https://github.com/MichalGeyer/plug-and-play)]

**BBDM: Image-to-image Translation with Brownian Bridge Diffusion Models.**<br>
*Bo Li, Kaitao Xue, Bin Liu and Yu-Kun Lai.*<br>
CVPR2023. [[PDF](https://arxiv.org/abs/2205.07680)]

**Dual Diffusion Implicit Bridges for Image-to-Image Translation.**<br>
*Xuan Su, Jiaming Song, Chenlin Meng and Stefano Ermon.*<br>
ICLR2023. [[PDF](https://arxiv.org/abs/2203.08382)] <br>
[[Github](https://github.com/suxuann/ddib)]

**Diffusion-based Image Translation using Disentangled Style and Content Representation.**<br>
*Gihyun Kwon and Jong Chul Ye.*<br>
ICLR2023. [[PDF](https://arxiv.org/abs/2209.15264)] <br>
[[Project](https://pnp-diffusion.github.io)] [[Github](https://github.com/anon294384/DiffuseIT)]

**Inversion-Based Style Transfer with Diffusion Models.**<br>
*Yuxin Zhang, Nisha Huang, Fan Tang, Haibin Huang, Chongyang Ma, Weiming Dong and Changsheng Xu.*<br>
arxiv2022. [[PDF](https://arxiv.org/abs/2211.13203)] <br>
[[Github](https://github.com/zyxElsa/InST)]

**DiffGAR: Model-Agnostic Restoration from Generative Artifacts Using Image-to-Image Diffusion Models.**<br>
*Yueqin Yin, Lianghua Huang, Yu Liu and Kaiqi Huang.*<br>
arxiv2022. [[PDF](https://arxiv.org/abs/2210.08573)]

**MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image Translation.**<br>
*Junyoung Seo, Gyuseong Lee, Seokju Cho, Jiyoung Lee and Seungryong Kim.*<br>
arxiv2022. [[PDF](https://arxiv.org/abs/2209.11047)] <br>
[[Project](https://ku-cvlab.github.io/MIDMs/)] [[Github](https://github.com/KU-CVLAB/MIDMs/)] 

**The Swiss Army Knife for Image-to-Image Translation: Multi-Task Diffusion Models.**<br>
*Julia Wolleb, Robin Sandkühler, Florentin Bieder and Philippe C. Cattin.*<br>
arxiv2022. [[PDF](https://arxiv.org/abs/2204.02641)]

## 2021

**DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation.**<br>
*Gwanghyun Kim, Taesung Kwon and Jong Chul Ye.*<br>
CVPR2022. [[PDF](https://arxiv.org/abs/2110.02711)] <br>
[[Github](https://github.com/gwang-kim/DiffusionCLIP
)]

**Palette: Image-to-Image Diffusion Models.**<br>
*Chitwan Saharia, William Chan, Huiwen Chang, Chris A. Lee, Jonathan Ho, Tim Salimans, David J. Fleet and Mohammad Norouzi.*<br>
SIGRAPH2021. [[PDF](https://arxiv.org/abs/2111.05826)]

**UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models.**<br>
*Hiroshi Sasaki, Chris G. Willcocks and Toby P. Breckon.*<br>
arxiv2021. [[PDF](https://arxiv.org/abs/2104.05358)]


